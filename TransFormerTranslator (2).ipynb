{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f483280"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import string\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "8f483280"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "862d819b"
      },
      "outputs": [],
      "source": [
        "file_loc=\"/content/spa.txt\"\n",
        "with open(file_loc) as f:\n",
        "    lines=f.read().split(\"\\n\")[:-1]\n",
        "data_pairs=[]\n",
        "for line in lines:\n",
        "    english, spanish=line.split(\"\\t\")\n",
        "    spanish=\"[start] \"+spanish+\" [end]\"\n",
        "    data_pairs.append((english,spanish))"
      ],
      "id": "862d819b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "734bc2a2",
        "outputId": "f425d86d-82a6-4281-a450-0bf2e14e7284"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "118964"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "len(data_pairs)"
      ],
      "id": "734bc2a2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0d0d4fe"
      },
      "outputs": [],
      "source": [
        "random.shuffle(data_pairs)"
      ],
      "id": "f0d0d4fe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d43b653c"
      },
      "outputs": [],
      "source": [
        "data_pairs"
      ],
      "id": "d43b653c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "448ee7f3"
      },
      "outputs": [],
      "source": [
        "train_data,test_data=train_test_split(data_pairs)"
      ],
      "id": "448ee7f3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "834acd6a"
      },
      "outputs": [],
      "source": [],
      "id": "834acd6a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "181d6c50"
      },
      "outputs": [],
      "source": [
        "train_data, val_data=train_test_split(train_data)"
      ],
      "id": "181d6c50"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7e36725",
        "outputId": "bd2c6b9f-63e1-4fb6-a748-40df7586f88e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66917 29741 22306\n"
          ]
        }
      ],
      "source": [
        "print(len(train_data),len(test_data),len(val_data))"
      ],
      "id": "d7e36725"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdea8e64"
      },
      "outputs": [],
      "source": [
        "strip_chars=string.punctuation+\"¿\"\n",
        "strip_chars=strip_chars.replace(\"[\",\"\")\n",
        "strip_chars=strip_chars.replace(\"]\",\"\")"
      ],
      "id": "cdea8e64"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5280d7e0",
        "outputId": "693d6059-dc41-479e-da37-c28bbd9af2f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@\\\\^_`{|}~¿'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "strip_chars"
      ],
      "id": "5280d7e0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "29fc5c4a",
        "outputId": "92f57077-ceeb-4f60-d750-2c67ec35e2ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[!\"\\\\#\\\\$%\\\\&\\'\\\\(\\\\)\\\\*\\\\+,\\\\-\\\\./:;<=>\\\\?@\\\\\\\\\\\\^_`\\\\{\\\\|\\\\}\\\\~¿]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "f\"[{re.escape(strip_chars)}]\""
      ],
      "id": "29fc5c4a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47eb1bee"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "def customStandardisation(input_string):\n",
        "    lowercase=tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase,f\"[{re.escape(strip_chars)}]\",\"\")"
      ],
      "id": "47eb1bee"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d55b4dcc"
      },
      "outputs": [],
      "source": [
        "vocab_size=15000\n",
        "sequence_length=20"
      ],
      "id": "d55b4dcc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c189f38"
      },
      "outputs": [],
      "source": [
        "english_vectorization=layers.experimental.preprocessing.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length)"
      ],
      "id": "9c189f38"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2041d35c"
      },
      "outputs": [],
      "source": [
        "spanish_vectorization=layers.experimental.preprocessing.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length+1,\n",
        "    standardize=customStandardisation)"
      ],
      "id": "2041d35c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0356c036"
      },
      "outputs": [],
      "source": [
        "train_english_texts=[pair[0] for pair in train_data]\n",
        "train_spanish_texts=[pair[1] for pair in train_data]"
      ],
      "id": "0356c036"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc334b7e"
      },
      "outputs": [],
      "source": [
        "english_vectorization.adapt(train_english_texts)\n",
        "spanish_vectorization.adapt(train_spanish_texts)"
      ],
      "id": "bc334b7e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50c4906d",
        "outputId": "e7d0813a-c4ec-457c-9e31-6c6446517b30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.preprocessing.text_vectorization.TextVectorization at 0x7efeb666ddf0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "english_vectorization"
      ],
      "id": "50c4906d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b1871ba"
      },
      "outputs": [],
      "source": [
        "batch_size=64\n",
        "def format_dataset(eng,spa):\n",
        "    eng=english_vectorization(eng)\n",
        "    spa=spanish_vectorization(spa)\n",
        "    return ({\"english\":eng,\"spanish\":spa[:,:-1],},spa[:,1:])\n",
        "def make_dataset(pairs):\n",
        "    eng_texts,spa_texts=zip(*pairs)\n",
        "    eng_texts=list(eng_texts)\n",
        "    spa_texts=list(spa_texts)\n",
        "    dataset=tf.data.Dataset.from_tensor_slices((eng_texts,spa_texts))\n",
        "    dataset=dataset.batch(batch_size)\n",
        "    dataset=dataset.map(format_dataset,num_parallel_calls=4)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()"
      ],
      "id": "9b1871ba"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baf52f40"
      },
      "outputs": [],
      "source": [
        "train_ds=make_dataset(train_data)\n",
        "val_ds=make_dataset(val_data)"
      ],
      "id": "baf52f40"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bc27e94",
        "outputId": "bdaecfdd-2d79-44d5-ff37-1728fc06a024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'english': array([[   5,  101, 1630, ...,    0,    0,    0],\n",
            "       [2452,   23, 1172, ...,    0,    0,    0],\n",
            "       [  40,    3,  145, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [  21,  251,   37, ...,    0,    0,    0],\n",
            "       [  21,   14, 5315, ...,    0,    0,    0],\n",
            "       [   3,  496,   10, ...,    0,    0,    0]]), 'spanish': array([[   2,   50,   12, ...,    0,    0,    0],\n",
            "       [   2,   20, 3088, ...,    0,    0,    0],\n",
            "       [   2,   54,  172, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [   2,   26,  136, ...,    0,    0,    0],\n",
            "       [   2,   26,   15, ...,    0,    0,    0],\n",
            "       [   2,   35, 1094, ...,    0,    0,    0]])}, array([[   50,    12,   529, ...,     0,     0,     0],\n",
            "       [   20,  3088,    15, ...,     0,     0,     0],\n",
            "       [   54,   172,    56, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [   26,   136,    18, ...,     0,     0,     0],\n",
            "       [   26,    15, 11189, ...,     0,     0,     0],\n",
            "       [   35,  1094,    11, ...,     0,     0,     0]]))\n"
          ]
        }
      ],
      "source": [
        "print(list(train_ds.as_numpy_iterator())[50])"
      ],
      "id": "1bc27e94"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71dcbaac"
      },
      "outputs": [],
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 1024"
      ],
      "id": "71dcbaac"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24fc7dca"
      },
      "outputs": [],
      "source": [
        "spa_vocab = spanish_vectorization.get_vocabulary()"
      ],
      "id": "24fc7dca"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f510dce7"
      },
      "outputs": [],
      "source": [
        "spa_vocab"
      ],
      "id": "f510dce7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2b9a29d"
      },
      "outputs": [],
      "source": [
        "spa_index_lookup=dict(zip(range(len(spa_vocab)),spa_vocab))"
      ],
      "id": "d2b9a29d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44857908"
      },
      "outputs": [],
      "source": [
        "max_decoded_sentence_length=20"
      ],
      "id": "44857908"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46962881"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self,embed_dim,dense_dim,num_heads,**kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim=embed_dim\n",
        "        self.dense_dim=dense_dim\n",
        "        self.num_heads=num_heads\n",
        "        self.attention=layers.MultiHeadAttention(\n",
        "        num_heads=num_heads,key_dim=embed_dim)\n",
        "        self.dense_proj=tf.keras.Sequential(\n",
        "        [layers.Dense(dense_dim, activation='relu'),layers.Dense(embed_dim),])\n",
        "        self.layernorm_1=layers.LayerNormalization()\n",
        "        self.layernorm_2=layers.LayerNormalization()\n",
        "        \n",
        "    def call(self,inputs,mask=None):\n",
        "        if mask is not None:\n",
        "            mask=mask[:,tf.newaxis,:]\n",
        "        attention_output=self.attention(inputs,inputs,attention_mask=mask)\n",
        "        proj_input=self.layernorm_1(inputs+attention_output)\n",
        "        proj_output=self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input+proj_output)\n",
        "#     def get_config(self)\n"
      ],
      "id": "46962881"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e794abc"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self,embed_dim,dense_dim,num_heads,**kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim=embed_dim\n",
        "        self.dense_dim=dense_dim\n",
        "        self.num_heads=num_heads\n",
        "        self.attention_1=layers.MultiHeadAttention(\n",
        "        num_heads=num_heads,key_dim=embed_dim)\n",
        "        self.attention_2=layers.MultiHeadAttention(\n",
        "        num_heads=num_heads,key_dim=embed_dim)\n",
        "        self.dense_proj=tf.keras.Sequential(\n",
        "        [layers.Dense(dense_dim,activation='relu'),\n",
        "         layers.Dense(embed_dim),])\n",
        "        self.layernorm_1=layers.LayerNormalization()\n",
        "        self.layernorm_2=layers.LayerNormalization()\n",
        "        self.layernorm_3=layers.LayerNormalization()\n",
        "        self.supports_masking=True\n",
        "        \n",
        "#     def get_config(self):\n",
        "\n",
        "    def get_casual_attention_mask(self,inputs):\n",
        "        input_shape=tf.shape(inputs)\n",
        "        batch_size, sequence_length=input_shape[0],input_shape[1]\n",
        "        i=tf.range(sequence_length)[:,tf.newaxis]\n",
        "        j=tf.range(sequence_length)\n",
        "        mask=tf.cast(i>=j,dtype='int32')\n",
        "        mask=tf.reshape(mask,(1,input_shape[1],input_shape[1]))\n",
        "        mult=tf.concat(\n",
        "        [tf.expand_dims(batch_size,-1),tf.constant([1,1],dtype=tf.int32)],axis=0)\n",
        "        return tf.tile(mask,mult)\n",
        "    \n",
        "    def call(self,inputs,encoder_outputs,mask=None):\n",
        "        casual_mask=self.get_casual_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:,tf.newaxis,:],dtype=\"int32\")\n",
        "            padding_mask=tf.minimum(padding_mask,casual_mask)\n",
        "            \n",
        "        attention_output_1=self.attention_1(\n",
        "        query=inputs,\n",
        "        value=inputs,\n",
        "        key=inputs,\n",
        "        attention_mask=casual_mask)\n",
        "        \n",
        "        attention_output_1=self.layernorm_1(inputs+attention_output_1)\n",
        "        \n",
        "        attention_output_2=self.attention_2(\n",
        "        query=attention_output_1,\n",
        "        value=encoder_outputs,\n",
        "        key=encoder_outputs,\n",
        "        attention_mask=padding_mask,)\n",
        "        \n",
        "        attention_output_2=self.layernorm_2(attention_output_1+attention_output_2)\n",
        "        proj_output=self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2+proj_output)"
      ],
      "id": "5e794abc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0e408ec"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config"
      ],
      "id": "c0e408ec"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b75975d"
      },
      "outputs": [],
      "source": [
        "embed_dim=256\n",
        "dense_dim=2048\n",
        "num_heads=8\n",
        "\n",
        "encoder_inputs=tf.keras.Input(shape=(None,),dtype=\"int64\",name='english')\n",
        "x=PositionalEmbedding(sequence_length,vocab_size,embed_dim)(encoder_inputs)\n",
        "encoder_outputs=TransformerEncoder(embed_dim,dense_dim,num_heads)(x)\n",
        "\n",
        "decoder_inputs = tf.keras.Input(shape=(None,),dtype=\"int64\",name=\"spanish\")\n",
        "x=PositionalEmbedding(sequence_length,vocab_size,embed_dim)(decoder_inputs)\n",
        "x=TransformerDecoder(embed_dim,dense_dim,num_heads)(x,encoder_outputs)\n",
        "\n",
        "x=layers.Dropout(0.5)(x)\n",
        "\n",
        "decoder_outputs=layers.Dense(vocab_size,activation=\"softmax\")(x)\n",
        "transformer=tf.keras.Model([encoder_inputs,decoder_inputs],decoder_outputs)"
      ],
      "id": "5b75975d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2e92140",
        "outputId": "f52f4a55-61fe-4488-f6c2-5b241769542f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " english (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " spanish (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " positional_embedding (Position  (None, None, 256)   3845120     ['english[0][0]']                \n",
            " alEmbedding)                                                                                     \n",
            "                                                                                                  \n",
            " positional_embedding_1 (Positi  (None, None, 256)   3845120     ['spanish[0][0]']                \n",
            " onalEmbedding)                                                                                   \n",
            "                                                                                                  \n",
            " transformer_encoder (Transform  (None, None, 256)   3155456     ['positional_embedding[0][0]']   \n",
            " erEncoder)                                                                                       \n",
            "                                                                                                  \n",
            " transformer_decoder (Transform  (None, None, 256)   5259520     ['positional_embedding_1[0][0]', \n",
            " erDecoder)                                                       'transformer_encoder[0][0]']    \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, None, 256)    0           ['transformer_decoder[0][0]']    \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, None, 15000)  3855000     ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19,960,216\n",
            "Trainable params: 19,960,216\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "transformer.summary()"
      ],
      "id": "b2e92140"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "992e87a7"
      },
      "outputs": [],
      "source": [
        "transformer.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "id": "992e87a7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bc2890a",
        "scrolled": true,
        "outputId": "2571a90c-2fd1-4ead-dbde-2d2c5f2f3ca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1046/1046 [==============================] - 105s 88ms/step - loss: 3.6342 - accuracy: 0.4575 - val_loss: 2.4864 - val_accuracy: 0.5723\n",
            "Epoch 2/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 2.3660 - accuracy: 0.5995 - val_loss: 1.9835 - val_accuracy: 0.6387\n",
            "Epoch 3/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 1.8646 - accuracy: 0.6579 - val_loss: 1.8114 - val_accuracy: 0.6615\n",
            "Epoch 4/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 1.5619 - accuracy: 0.6943 - val_loss: 1.7474 - val_accuracy: 0.6732\n",
            "Epoch 5/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 1.3542 - accuracy: 0.7198 - val_loss: 1.7021 - val_accuracy: 0.6807\n",
            "Epoch 6/100\n",
            "1046/1046 [==============================] - 75s 71ms/step - loss: 1.2005 - accuracy: 0.7421 - val_loss: 1.7012 - val_accuracy: 0.6866\n",
            "Epoch 7/100\n",
            "1046/1046 [==============================] - 84s 80ms/step - loss: 1.0782 - accuracy: 0.7594 - val_loss: 1.7193 - val_accuracy: 0.6905\n",
            "Epoch 8/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.9794 - accuracy: 0.7761 - val_loss: 1.7179 - val_accuracy: 0.6910\n",
            "Epoch 9/100\n",
            "1046/1046 [==============================] - 75s 71ms/step - loss: 0.8989 - accuracy: 0.7902 - val_loss: 1.7666 - val_accuracy: 0.6854\n",
            "Epoch 10/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.8350 - accuracy: 0.8019 - val_loss: 1.7669 - val_accuracy: 0.6903\n",
            "Epoch 11/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.7782 - accuracy: 0.8120 - val_loss: 1.8098 - val_accuracy: 0.6881\n",
            "Epoch 12/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.7255 - accuracy: 0.8221 - val_loss: 1.8430 - val_accuracy: 0.6963\n",
            "Epoch 13/100\n",
            "1046/1046 [==============================] - 85s 81ms/step - loss: 0.6848 - accuracy: 0.8308 - val_loss: 1.8626 - val_accuracy: 0.6953\n",
            "Epoch 14/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.6483 - accuracy: 0.8377 - val_loss: 1.9152 - val_accuracy: 0.6968\n",
            "Epoch 15/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.6142 - accuracy: 0.8447 - val_loss: 1.9664 - val_accuracy: 0.6964\n",
            "Epoch 16/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.5849 - accuracy: 0.8508 - val_loss: 1.9508 - val_accuracy: 0.6955\n",
            "Epoch 17/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.5573 - accuracy: 0.8568 - val_loss: 1.9704 - val_accuracy: 0.6977\n",
            "Epoch 18/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.5280 - accuracy: 0.8630 - val_loss: 2.0319 - val_accuracy: 0.6961\n",
            "Epoch 19/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.5061 - accuracy: 0.8674 - val_loss: 2.0657 - val_accuracy: 0.6955\n",
            "Epoch 20/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.4826 - accuracy: 0.8732 - val_loss: 2.1001 - val_accuracy: 0.6943\n",
            "Epoch 21/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.4647 - accuracy: 0.8771 - val_loss: 2.1244 - val_accuracy: 0.6966\n",
            "Epoch 22/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.4484 - accuracy: 0.8803 - val_loss: 2.1760 - val_accuracy: 0.6972\n",
            "Epoch 23/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.4295 - accuracy: 0.8852 - val_loss: 2.1398 - val_accuracy: 0.6982\n",
            "Epoch 24/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.4124 - accuracy: 0.8891 - val_loss: 2.1920 - val_accuracy: 0.6978\n",
            "Epoch 25/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.3948 - accuracy: 0.8928 - val_loss: 2.2159 - val_accuracy: 0.6972\n",
            "Epoch 26/100\n",
            "1046/1046 [==============================] - 84s 81ms/step - loss: 0.3816 - accuracy: 0.8963 - val_loss: 2.2103 - val_accuracy: 0.6966\n",
            "Epoch 27/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.3699 - accuracy: 0.8991 - val_loss: 2.2293 - val_accuracy: 0.6962\n",
            "Epoch 28/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.3581 - accuracy: 0.9016 - val_loss: 2.2619 - val_accuracy: 0.6951\n",
            "Epoch 29/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.3457 - accuracy: 0.9046 - val_loss: 2.2807 - val_accuracy: 0.6957\n",
            "Epoch 30/100\n",
            "1046/1046 [==============================] - 74s 71ms/step - loss: 0.3362 - accuracy: 0.9071 - val_loss: 2.2827 - val_accuracy: 0.6959\n",
            "Epoch 31/100\n",
            "1046/1046 [==============================] - 74s 71ms/step - loss: 0.3233 - accuracy: 0.9103 - val_loss: 2.3340 - val_accuracy: 0.6932\n",
            "Epoch 32/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.3179 - accuracy: 0.9112 - val_loss: 2.3464 - val_accuracy: 0.6951\n",
            "Epoch 33/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.3074 - accuracy: 0.9145 - val_loss: 2.3582 - val_accuracy: 0.6956\n",
            "Epoch 34/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.2951 - accuracy: 0.9174 - val_loss: 2.3819 - val_accuracy: 0.6951\n",
            "Epoch 35/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.2897 - accuracy: 0.9188 - val_loss: 2.4074 - val_accuracy: 0.6955\n",
            "Epoch 36/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.2827 - accuracy: 0.9211 - val_loss: 2.4229 - val_accuracy: 0.6947\n",
            "Epoch 37/100\n",
            "1046/1046 [==============================] - 75s 71ms/step - loss: 0.2764 - accuracy: 0.9223 - val_loss: 2.4291 - val_accuracy: 0.6950\n",
            "Epoch 38/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.2664 - accuracy: 0.9250 - val_loss: 2.4635 - val_accuracy: 0.6938\n",
            "Epoch 39/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.2601 - accuracy: 0.9263 - val_loss: 2.4664 - val_accuracy: 0.6937\n",
            "Epoch 40/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.2552 - accuracy: 0.9277 - val_loss: 2.4736 - val_accuracy: 0.6954\n",
            "Epoch 41/100\n",
            "1046/1046 [==============================] - 75s 71ms/step - loss: 0.2512 - accuracy: 0.9285 - val_loss: 2.5144 - val_accuracy: 0.6933\n",
            "Epoch 42/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.2419 - accuracy: 0.9309 - val_loss: 2.4713 - val_accuracy: 0.6934\n",
            "Epoch 43/100\n",
            "1046/1046 [==============================] - 75s 71ms/step - loss: 0.2372 - accuracy: 0.9326 - val_loss: 2.5139 - val_accuracy: 0.6934\n",
            "Epoch 44/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.2347 - accuracy: 0.9338 - val_loss: 2.5447 - val_accuracy: 0.6954\n",
            "Epoch 45/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.2268 - accuracy: 0.9350 - val_loss: 2.5476 - val_accuracy: 0.6959\n",
            "Epoch 46/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.2232 - accuracy: 0.9360 - val_loss: 2.5582 - val_accuracy: 0.6954\n",
            "Epoch 47/100\n",
            "1046/1046 [==============================] - 75s 71ms/step - loss: 0.2183 - accuracy: 0.9375 - val_loss: 2.5995 - val_accuracy: 0.6935\n",
            "Epoch 48/100\n",
            "1046/1046 [==============================] - 75s 71ms/step - loss: 0.2164 - accuracy: 0.9381 - val_loss: 2.5723 - val_accuracy: 0.6937\n",
            "Epoch 49/100\n",
            "1046/1046 [==============================] - 75s 71ms/step - loss: 0.2113 - accuracy: 0.9392 - val_loss: 2.6189 - val_accuracy: 0.6940\n",
            "Epoch 50/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.2067 - accuracy: 0.9404 - val_loss: 2.6270 - val_accuracy: 0.6941\n",
            "Epoch 51/100\n",
            "1046/1046 [==============================] - 75s 71ms/step - loss: 0.2040 - accuracy: 0.9416 - val_loss: 2.6032 - val_accuracy: 0.6940\n",
            "Epoch 52/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1981 - accuracy: 0.9429 - val_loss: 2.6444 - val_accuracy: 0.6931\n",
            "Epoch 53/100\n",
            "1046/1046 [==============================] - 84s 81ms/step - loss: 0.1968 - accuracy: 0.9435 - val_loss: 2.6172 - val_accuracy: 0.6935\n",
            "Epoch 54/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1917 - accuracy: 0.9445 - val_loss: 2.7092 - val_accuracy: 0.6927\n",
            "Epoch 55/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1906 - accuracy: 0.9453 - val_loss: 2.6731 - val_accuracy: 0.6936\n",
            "Epoch 56/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1876 - accuracy: 0.9458 - val_loss: 2.6528 - val_accuracy: 0.6930\n",
            "Epoch 57/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1820 - accuracy: 0.9471 - val_loss: 2.6630 - val_accuracy: 0.6930\n",
            "Epoch 58/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1784 - accuracy: 0.9482 - val_loss: 2.6980 - val_accuracy: 0.6949\n",
            "Epoch 59/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1779 - accuracy: 0.9486 - val_loss: 2.6711 - val_accuracy: 0.6943\n",
            "Epoch 60/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1738 - accuracy: 0.9496 - val_loss: 2.7208 - val_accuracy: 0.6921\n",
            "Epoch 61/100\n",
            "1046/1046 [==============================] - 75s 71ms/step - loss: 0.1731 - accuracy: 0.9499 - val_loss: 2.6762 - val_accuracy: 0.6934\n",
            "Epoch 62/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1678 - accuracy: 0.9510 - val_loss: 2.7092 - val_accuracy: 0.6911\n",
            "Epoch 63/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1672 - accuracy: 0.9517 - val_loss: 2.7801 - val_accuracy: 0.6905\n",
            "Epoch 64/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1649 - accuracy: 0.9522 - val_loss: 2.7779 - val_accuracy: 0.6908\n",
            "Epoch 65/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1611 - accuracy: 0.9530 - val_loss: 2.7670 - val_accuracy: 0.6915\n",
            "Epoch 66/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1590 - accuracy: 0.9533 - val_loss: 2.7834 - val_accuracy: 0.6931\n",
            "Epoch 67/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1560 - accuracy: 0.9544 - val_loss: 2.7582 - val_accuracy: 0.6934\n",
            "Epoch 68/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1548 - accuracy: 0.9549 - val_loss: 2.7866 - val_accuracy: 0.6921\n",
            "Epoch 69/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1539 - accuracy: 0.9552 - val_loss: 2.8186 - val_accuracy: 0.6915\n",
            "Epoch 70/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1505 - accuracy: 0.9559 - val_loss: 2.7702 - val_accuracy: 0.6933\n",
            "Epoch 71/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1486 - accuracy: 0.9566 - val_loss: 2.8000 - val_accuracy: 0.6907\n",
            "Epoch 72/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1475 - accuracy: 0.9569 - val_loss: 2.8478 - val_accuracy: 0.6928\n",
            "Epoch 73/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1456 - accuracy: 0.9571 - val_loss: 2.8122 - val_accuracy: 0.6923\n",
            "Epoch 74/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1436 - accuracy: 0.9580 - val_loss: 2.8129 - val_accuracy: 0.6933\n",
            "Epoch 75/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1427 - accuracy: 0.9581 - val_loss: 2.8630 - val_accuracy: 0.6913\n",
            "Epoch 76/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1389 - accuracy: 0.9592 - val_loss: 2.8927 - val_accuracy: 0.6902\n",
            "Epoch 77/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1373 - accuracy: 0.9597 - val_loss: 2.8089 - val_accuracy: 0.6926\n",
            "Epoch 78/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1363 - accuracy: 0.9598 - val_loss: 2.9132 - val_accuracy: 0.6878\n",
            "Epoch 79/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1358 - accuracy: 0.9598 - val_loss: 2.9171 - val_accuracy: 0.6906\n",
            "Epoch 80/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1345 - accuracy: 0.9605 - val_loss: 2.8626 - val_accuracy: 0.6925\n",
            "Epoch 81/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1309 - accuracy: 0.9616 - val_loss: 2.9158 - val_accuracy: 0.6925\n",
            "Epoch 82/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1306 - accuracy: 0.9615 - val_loss: 2.8526 - val_accuracy: 0.6909\n",
            "Epoch 83/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1299 - accuracy: 0.9620 - val_loss: 2.8567 - val_accuracy: 0.6924\n",
            "Epoch 84/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1281 - accuracy: 0.9620 - val_loss: 2.9005 - val_accuracy: 0.6889\n",
            "Epoch 85/100\n",
            "1046/1046 [==============================] - 84s 81ms/step - loss: 0.1274 - accuracy: 0.9624 - val_loss: 2.9028 - val_accuracy: 0.6912\n",
            "Epoch 86/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1229 - accuracy: 0.9637 - val_loss: 2.9271 - val_accuracy: 0.6903\n",
            "Epoch 87/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1227 - accuracy: 0.9640 - val_loss: 2.9718 - val_accuracy: 0.6882\n",
            "Epoch 88/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1229 - accuracy: 0.9637 - val_loss: 2.9048 - val_accuracy: 0.6894\n",
            "Epoch 89/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1209 - accuracy: 0.9645 - val_loss: 2.9346 - val_accuracy: 0.6881\n",
            "Epoch 90/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1185 - accuracy: 0.9649 - val_loss: 3.0090 - val_accuracy: 0.6892\n",
            "Epoch 91/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1204 - accuracy: 0.9646 - val_loss: 3.0040 - val_accuracy: 0.6886\n",
            "Epoch 92/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1196 - accuracy: 0.9647 - val_loss: 2.9280 - val_accuracy: 0.6894\n",
            "Epoch 93/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1153 - accuracy: 0.9659 - val_loss: 3.0404 - val_accuracy: 0.6913\n",
            "Epoch 94/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1150 - accuracy: 0.9659 - val_loss: 2.9860 - val_accuracy: 0.6884\n",
            "Epoch 95/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1159 - accuracy: 0.9659 - val_loss: 2.9901 - val_accuracy: 0.6910\n",
            "Epoch 96/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1110 - accuracy: 0.9670 - val_loss: 3.0405 - val_accuracy: 0.6893\n",
            "Epoch 97/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1115 - accuracy: 0.9670 - val_loss: 3.0571 - val_accuracy: 0.6870\n",
            "Epoch 98/100\n",
            "1046/1046 [==============================] - 75s 72ms/step - loss: 0.1122 - accuracy: 0.9668 - val_loss: 3.0103 - val_accuracy: 0.6884\n",
            "Epoch 99/100\n",
            "1046/1046 [==============================] - 75s 71ms/step - loss: 0.1102 - accuracy: 0.9671 - val_loss: 3.0306 - val_accuracy: 0.6880\n",
            "Epoch 100/100\n",
            "1046/1046 [==============================] - 75s 71ms/step - loss: 0.1094 - accuracy: 0.9677 - val_loss: 2.9866 - val_accuracy: 0.6895\n"
          ]
        }
      ],
      "source": [
        "stats=transformer.fit(train_ds,epochs=100,batch_size=32,validation_data=val_ds)"
      ],
      "id": "7bc2890a"
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.save(\"/content/model.h5\")"
      ],
      "metadata": {
        "id": "sU36N0NUJQ12"
      },
      "id": "sU36N0NUJQ12",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3946e028"
      },
      "outputs": [],
      "source": [
        "spa_vocab=spanish_vectorization.get_vocabulary()\n",
        "spa_index_lookup=dict(zip(range(len(spa_vocab)),spa_vocab))\n",
        "max_decoded_sentence_length=20\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence=spanish_vectorization([input_sentence])\n",
        "    decoded_sentence=\"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence=spanish_vectorization([decoded_sentence])[:,:,-1]\n",
        "        predictions=transformer([tokenized_input_sentence,tokenized_target_sentence])\n",
        "        sampled_token_index=np.argmax(predictions[0,i,:])\n",
        "        sampled_token=spa_index_lookup(sampled_token_index)\n",
        "        decoded_sentence+=\" \"+sampled_token\n",
        "        if sampled_token==\"[end]\":\n",
        "            break\n",
        "        return decoded_sentence\n",
        "\n",
        "test_eng_texts=[pair[0] for pair in test_data]\n",
        "\n",
        "for _ in range(20):\n",
        "    input_sentence=random.choice(test_eng_texts)"
      ],
      "id": "3946e028"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python [conda env:tensorenv] *",
      "language": "python",
      "name": "conda-env-tensorenv-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}